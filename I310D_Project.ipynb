{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC_lSsO4iWWZ"
      },
      "source": [
        "#Telco Customer Churn\n",
        "\n",
        "Documentation: https://www.ibm.com/docs/en/cognos-analytics/12.1.x?topic=samples-telco-customer-churn\n",
        "\n",
        "Local path: /content/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
        "* Dataset must be loaded into Google Colab each time\n",
        "* Dataset is available in the GitHub repository (https://github.com/lydsleepy/machine-learning)\n",
        "\n",
        "Path if cloned GitHub repo: /content/machine-learning/I310D_Project.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5N1I_xjkJPr",
        "outputId": "ed955e70-29bf-4b83-f221-b98075af8851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/WA_Fn-UseC_-Telco-Customer-Churn.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1159570770.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mREPO_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/machine-learning/I310D_Project.ipynb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# we'll use local path for now since not everyone might be in github\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
          ]
        }
      ],
      "source": [
        "'''IMPORTS AND LOADING'''\n",
        "# test\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "# loading data\n",
        "LOCAL_PATH = \"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "REPO_PATH = \"/content/machine-learning/I310D_Project.ipynb\"\n",
        "# we'll use local path for now since not everyone might be in github\n",
        "df = pd.read_csv(LOCAL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XymXZYhk0xU"
      },
      "outputs": [],
      "source": [
        "# what does our dataset look like?\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fq5d-LOlrCo"
      },
      "outputs": [],
      "source": [
        "# what are our values?\n",
        "df.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P26Et_I-Zfgz"
      },
      "outputs": [],
      "source": [
        "'''DATA CLEANING AND SANITIZATION'''\n",
        "# check if there are any duplicates\n",
        "number_of_duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicates: {number_of_duplicates}\")\n",
        "# There are no duplicates to remove\n",
        "\n",
        "# Check if there are any null values\n",
        "df.info()\n",
        "# There are no null cells/values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLLVQzijYOxj"
      },
      "outputs": [],
      "source": [
        "# Check for blank values\n",
        "for column in df:\n",
        "  blank = list(df[column])\n",
        "  sum = 0\n",
        "  for item in blank:\n",
        "    if item == ' ' or item == '' or item == 'NA' or item == 'NaN' or pd.isna(item):\n",
        "      sum += 1\n",
        "\n",
        "  print(f\"{column} blank values: {sum}\")\n",
        "\n",
        "# It looks like there are 11 blank values in TotalCharges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK8nCDR7bl2l"
      },
      "outputs": [],
      "source": [
        "# drop the rows that have a blank value for TotalCharges\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmQXtvGYcQVy"
      },
      "outputs": [],
      "source": [
        "# check that the blanks were dropped successfully\n",
        "for column in df:\n",
        "  blank = list(df[column])\n",
        "  sum = 0\n",
        "  for item in blank:\n",
        "    if item == ' ' or item == '' or item == 'NA' or item == 'NaN' or pd.isna(item):\n",
        "      sum += 1\n",
        "\n",
        "  print(f\"{column} blank values: {sum}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6jXgsK0IO0e"
      },
      "outputs": [],
      "source": [
        "# we want to exclude protected attributes to minimize bias\n",
        "feature_columns = [\"Partner\", \"Dependents\",\n",
        "                   \"tenure\", \"PhoneService\", \"MultipleLines\",\n",
        "                   \"InternetService\", \"OnlineSecurity\",\n",
        "                   \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
        "                   \"StreamingTV\", \"StreamingMovies\", \"Contract\",\n",
        "                   \"PaperlessBilling\", \"PaymentMethod\", \"MonthlyCharges\",\n",
        "                   \"TotalCharges\", \"Churn\"]\n",
        "\n",
        "churn_data = df[feature_columns]\n",
        "churn_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYv1gaNZKBEN"
      },
      "outputs": [],
      "source": [
        "# A lot of the columns are in string format.\n",
        "# We will convert them into integers\n",
        "churn_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVf2iffAO0V_"
      },
      "outputs": [],
      "source": [
        "# to assist with converting, see all the unique values for each column\n",
        "for column in churn_data:\n",
        "  print(f\"{column} values: {churn_data[column].unique()}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7m0dCbGKWlc"
      },
      "outputs": [],
      "source": [
        "'''FEATURE ENGINEERING'''\n",
        "\n",
        "def featurize(df):\n",
        "  # 'X' is the df that will hold our converted data\n",
        "  X = df[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "  X['Partner'] = [1 if x=='Yes' else 0 for x in df['Partner']]\n",
        "  X['Dependents'] = [1 if x=='Yes' else 0 for x in df['Dependents']]\n",
        "  X['PhoneService'] = [1 if x=='Yes' else 0 for x in df['PhoneService']]\n",
        "  X['MultipleLines'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['MultipleLines']]\n",
        "  X['InternetService'] = [1 if x=='DSL' else 0 if x=='Fiber optic' else 2 for x in df['InternetService']]\n",
        "  X['OnlineSecurity'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['OnlineSecurity']]\n",
        "  X['OnlineBackup'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['OnlineBackup']]\n",
        "  X['DeviceProtection'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['DeviceProtection']]\n",
        "  X['TechSupport'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['TechSupport']]\n",
        "  X['StreamingTV'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['StreamingTV']]\n",
        "  X['StreamingMovies'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['StreamingMovies']]\n",
        "  X['Contract'] = [1 if x=='Month-to-month' else 0 if x=='One year' else 2 for x in df['Contract']]\n",
        "  X['PaperlessBilling'] = [1 if x=='Yes' else 0 for x in df['PaperlessBilling']]\n",
        "  X['PaymentMethod'] = [1 if x=='Electronic check'\n",
        "                        else 0 if x=='Mailed check'\n",
        "                        else 2 if x=='Bank transfer (automatic)'\n",
        "                        else 3 for x in df['PaymentMethod']]\n",
        "\n",
        "  return X\n",
        "\n",
        "\n",
        "# Also convert 'Churn' into 0/1 format\n",
        "x_test_churn = featurize(churn_data)\n",
        "y_actual_churn = [1 if y == 'Yes' else 0 for y in churn_data['Churn']]\n",
        "\n",
        "churn_labels = pd.DataFrame(y_actual_churn, columns=[\"Churn\"])\n",
        "\n",
        "display(x_test_churn.head())\n",
        "display(churn_labels.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln07oNuqZhwg"
      },
      "outputs": [],
      "source": [
        "'''EXPLORATORY DATA ANALYSIS'''\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.core.interactiveshell import InteractiveShell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD1FyrS2cdSu"
      },
      "outputs": [],
      "source": [
        "#GRAPH COMPARING THE MONTHLY PAYMENTS FOR CUSTOMERS WHO WERE AND WERENT CHURNED\n",
        "\n",
        "#Setting up Datasets\n",
        "monthlycharge_column = x_test_churn[\"MonthlyCharges\"]\n",
        "monthly_charge = []\n",
        "no_churn = []\n",
        "yes_churn = []\n",
        "\n",
        "#creating a list of the monthly charges values\n",
        "for num in monthlycharge_column:\n",
        "  monthly_charge.append(num)\n",
        "\n",
        "#seperating the monthly charges into 2 new lists - customers that were and were not churned\n",
        "x=0\n",
        "for y in y_actual_churn:\n",
        "  if y == 0:\n",
        "    no_churn.append(monthly_charge[x])\n",
        "  elif y == 1:\n",
        "    yes_churn.append(monthly_charge[x])\n",
        "  x+=1\n",
        "\n",
        "#Creating the boxplot of to compare these two groups\n",
        "plt.boxplot([no_churn, yes_churn], labels=['No', 'Yes'])\n",
        "plt.title(\"Monthly Charges Depending on Churn Status\")\n",
        "plt.xlabel(\"Churned?\")\n",
        "plt.ylabel(\"Monthly Charge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPs_dLxt6IGf"
      },
      "outputs": [],
      "source": [
        "#GRAPH COMPARING THE TOTAL PAYMENTS FOR CUSTOMERS WHO WERE AND WERENT CHURNED\n",
        "\n",
        "#Setting up Datasets\n",
        "Totalcharge_column = x_test_churn[\"TotalCharges\"]\n",
        "total_charge = []\n",
        "no_churn = []\n",
        "yes_churn = []\n",
        "\n",
        "#creating a list of the monthly charges values\n",
        "for num in Totalcharge_column:\n",
        "  total_charge.append(num)\n",
        "\n",
        "#seperating the monthly charges into 2 new lists - customers that were and were not churned\n",
        "x=0\n",
        "for y in y_actual_churn:\n",
        "  if y == 0:\n",
        "    no_churn.append(total_charge[x])\n",
        "  elif y == 1:\n",
        "    yes_churn.append(total_charge[x])\n",
        "  x+=1\n",
        "\n",
        "#Creating the boxplot of to compare these two groups\n",
        "plt.boxplot([no_churn, yes_churn], labels=['No', 'Yes'])\n",
        "plt.title(\"Total Charges Depending on Churn Status\")\n",
        "plt.xlabel(\"Churned?\")\n",
        "plt.ylabel(\"Total Charge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLD929c35xvJ"
      },
      "outputs": [],
      "source": [
        "# GRAPH COMPARING THE TENURE FOR CUSTOMERS WHO WERE AND WERENT CHURNED\n",
        "\n",
        "# Setting up Datasets\n",
        "Tenure_column = x_test_churn[\"tenure\"]\n",
        "tenure= []\n",
        "no_churn = []\n",
        "yes_churn = []\n",
        "\n",
        "# creating a list of the monthly charges values\n",
        "for num in Tenure_column:\n",
        "  tenure.append(num)\n",
        "\n",
        "# seperating the monthly charges into 2 new lists - customers that were and were not churned\n",
        "x=0\n",
        "for y in y_actual_churn:\n",
        "  if y == 0:\n",
        "    no_churn.append(tenure[x])\n",
        "  elif y == 1:\n",
        "    yes_churn.append(tenure[x])\n",
        "  x+=1\n",
        "\n",
        "# Creating the boxplot of to compare these two groups\n",
        "plt.boxplot([no_churn, yes_churn], labels=['No', 'Yes'])\n",
        "plt.title(\"Tenure Depending on Churn Status\")\n",
        "plt.xlabel(\"Churned?\")\n",
        "plt.ylabel(\"Tenure\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRAPH COMPARING THE CHURNED STATUS ON INTERNET SERVICE\n",
        "#Setting up Datasets\n",
        "categories = [\"DSL\", \"Fiber optic\", \"No\"]\n",
        "internet_column = x_test_churn[\"InternetService\"]\n",
        "\n",
        "internet= []\n",
        "yes_churn = []\n",
        "no_churn = []\n",
        "\n",
        "no_churn_dsl =[]\n",
        "no_churn_fiberoptic = []\n",
        "no_churn_no = []\n",
        "\n",
        "yes_churn_dsl = []\n",
        "yes_churn_fiberoptic = []\n",
        "yes_churn_no = []\n",
        "\n",
        "#Creating a list of the internet services status\n",
        "for i in internet_column:\n",
        "  internet.append(i)\n",
        "\n",
        "#Seperating the Internet service status into 2 groups yes- if they churned, no- if they did not churn\n",
        "u=0\n",
        "for y in y_actual_churn:\n",
        "  if y == 0:\n",
        "    no_churn.append(internet[u])\n",
        "  elif y == 1:\n",
        "    yes_churn.append(internet[u])\n",
        "  u+=1\n",
        "\n",
        "\n",
        "#Seperating the non-churn group into a group depending on internet service\n",
        "\n",
        "for i in no_churn:\n",
        "  if i == 0:\n",
        "    no_churn_fiberoptic.append(i)\n",
        "  elif i == 1:\n",
        "    no_churn_dsl.append(i)\n",
        "  elif i == 2:\n",
        "    no_churn_no.append(i)\n",
        "#Seperating the churning group into a group depending on internet service\n",
        "for i in yes_churn:\n",
        "  if i == 0:\n",
        "    yes_churn_fiberoptic.append(i)\n",
        "  elif i == 1:\n",
        "    yes_churn_dsl.append(i)\n",
        "  elif i == 2:\n",
        "    yes_churn_no.append(i)\n",
        "#Setting up for plotting\n",
        "w=.4\n",
        "cat = np.arange(len(categories))\n",
        "\n",
        "#Bar plot comparing the internet service and who decided to churn or not\n",
        "plt.bar(cat - w/2, [len(no_churn_dsl), len(no_churn_fiberoptic), len(no_churn_no)], width=.4, label=\"Not Churning\")\n",
        "plt.bar(cat+ w/2, [len(yes_churn_dsl), len(yes_churn_fiberoptic), len(yes_churn_no)], width=.4,label=\"Churning\")\n",
        "\n",
        "\n",
        "#Labeling the bar plot\n",
        "plt.title(\"Internet Service Depending on Churn Status\")\n",
        "plt.xlabel(\"Internet Service Churned?\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.xticks(cat, categories)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "rQcMIQv2JhrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Vf06DGWow6"
      },
      "outputs": [],
      "source": [
        "#online security and churned data\n",
        "\n",
        "#Setting up Datasets\n",
        "categories = [\"Not use Online Security\",\"Use Online Security\", \"No internet service\"]\n",
        "online_column = x_test_churn[\"OnlineSecurity\"]\n",
        "\n",
        "security = []\n",
        "no_churn = []\n",
        "yes_churn = []\n",
        "\n",
        "no_churn_n_security =[]\n",
        "no_churn_y_security = []\n",
        "no_churn_no = []\n",
        "\n",
        "yes_churn_n_security = []\n",
        "yes_churn_y_security = []\n",
        "yes_churn_no = []\n",
        "\n",
        "#Creating a list of the online security status\n",
        "\n",
        "for i in online_column:\n",
        "  security.append(i)\n",
        "u=0\n",
        "for y in y_actual_churn:\n",
        "  if y == 0:\n",
        "    no_churn.append(security[u])\n",
        "  elif y == 1:\n",
        "    yes_churn.append(security[u])\n",
        "  u+=1\n",
        "#Seperating the online security status into 2 groups yes- if they churned, no- if they did not churn\n",
        "for y in no_churn:\n",
        "  if y == 0:\n",
        "    no_churn_n_security.append(y)\n",
        "  elif y == 1:\n",
        "    no_churn_y_security.append(y)\n",
        "  elif y == 2:\n",
        "    no_churn_no.append(y)\n",
        "for y in yes_churn:\n",
        "  if y == 0:\n",
        "    yes_churn_n_security.append(y)\n",
        "  elif y == 1:\n",
        "    yes_churn_y_security.append(y)\n",
        "  elif y == 2:\n",
        "    yes_churn_no.append(y)\n",
        "\n",
        "#Setting up for plotting\n",
        "w=.4\n",
        "cat = np.arange(len(categories))\n",
        "\n",
        "#Bar plot comparing the online security status and who decided to churn or not\n",
        "plt.bar(cat - w/2, [len(no_churn_n_security), len(no_churn_y_security), len(no_churn_no)], width=.4, label=\"Not Churning\")\n",
        "plt.bar(cat+ w/2, [len(yes_churn_n_security), len(yes_churn_y_security), len(yes_churn_no)], width=.4,label=\"Churning\")\n",
        "\n",
        "#Labeling the bar plot\n",
        "plt.title(\"Online Security Depending on Churn Status\")\n",
        "plt.xlabel(\"Online Security Churned?\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.xticks(cat, categories)\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIpDos52Zk5I"
      },
      "outputs": [],
      "source": [
        "'''MODEL TRAINING'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#display(x_test_churn.head())\n",
        "#display(churn_labels.head())\n",
        "\n",
        "# split datasets into training/temporary dataset on 70/30 split\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(\n",
        "    x_test_churn, churn_labels,\n",
        "    random_state = 104,\n",
        "    test_size = 0.30,\n",
        "    stratify = churn_labels\n",
        ")\n",
        "\n",
        "# split temporary dataset into validation/testing dataset on 50/50 split\n",
        "# each set has 15% of original data\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_temp, y_temp,\n",
        "    test_size = 0.50,\n",
        "    stratify = y_temp,\n",
        "    random_state = 104\n",
        ")\n",
        "\n",
        "print(\"New Training Datasets\")\n",
        "display(x_train.head())\n",
        "display(y_train.head())\n",
        "\n",
        "print(\"New Validation Datasets\")\n",
        "display(x_val.head())\n",
        "display(y_val.head())\n",
        "\n",
        "print(\"New Testing Datasets\")\n",
        "display(x_test.head())\n",
        "display(y_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model selection for Logistic Regression\n",
        "# This block will take ~1 min to run\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Cs = [0.01, 0.1, 1, 10]\n",
        "solvers = [\"lbfgs\", \"liblinear\"]\n",
        "weights = [None, \"balanced\"]\n",
        "\n",
        "lr_results = []\n",
        "\n",
        "for c in Cs:\n",
        "  for solver in solvers:\n",
        "    for weight in weights:\n",
        "\n",
        "      lr_classifier = LogisticRegression(\n",
        "          solver = solver,\n",
        "          max_iter = 10000,\n",
        "          C = c,\n",
        "          class_weight = weight,\n",
        "          random_state = 45\n",
        "      )\n",
        "\n",
        "      lr_classifier.fit(x_train.to_numpy(), y_train.to_numpy())\n",
        "\n",
        "      y_predicted_lr = lr_classifier.predict(x_val.to_numpy())\n",
        "      lr_accuracy_score = accuracy_score(y_val, y_predicted_lr)\n",
        "\n",
        "      lr_results.append((c, solver, weight, lr_accuracy_score))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yOrwwFO0OU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model selection for MLPClassifier\n",
        "# This block will take like 6 mins to run (sorry)\n",
        "\n",
        "alphas = [0.001, 0.0001, 0.00001]\n",
        "layers = [(8,2), (20,), (50,), (50,50)]\n",
        "\n",
        "mlp_results = []\n",
        "\n",
        "for alpha in alphas:\n",
        "  for layer in layers:\n",
        "\n",
        "    mlp_classifier = MLPClassifier(\n",
        "        solver = 'lbfgs',\n",
        "        alpha = alpha,\n",
        "        hidden_layer_sizes = layer,\n",
        "        random_state = 11,\n",
        "        max_iter = 10000\n",
        "    )\n",
        "\n",
        "    mlp_classifier.fit(x_train.to_numpy(), y_train.to_numpy())\n",
        "\n",
        "    y_predicted_mlp = mlp_classifier.predict(x_val.to_numpy())\n",
        "    mlp_accuracy_score = accuracy_score(y_val, y_predicted_mlp)\n",
        "\n",
        "    mlp_results.append((alpha, layer, mlp_accuracy_score))\n"
      ],
      "metadata": {
        "id": "ajmQ1vUO3IT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''MODEL EVALUATION'''\n",
        "\n",
        "print(\"Logistic Regression results (ascending order)\")\n",
        "lr_results.sort(key = lambda x : x[3])\n",
        "for result in lr_results:\n",
        "  print(result)\n",
        "\n",
        "print()\n",
        "print(\"MLPClassifier results (ascending order)\")\n",
        "mlp_results.sort(key = lambda x : x[2])\n",
        "for result in mlp_results:\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "PVIfGdbU3Dlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will use the highest performing models\n",
        "#            for LR/MLP on the actual test data\n",
        "\n",
        "# LR: (0.1, 'liblinear', None, 0.7962085308056872)\n",
        "# MLP: (0.001, (20,), 0.8075829383886256)\n",
        "\n",
        "final_lr = LogisticRegression(\n",
        "    C = 0.1,\n",
        "    solver = 'liblinear',\n",
        "    max_iter = 10000,\n",
        "    class_weight = None,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "final_mlp = MLPClassifier(\n",
        "    solver = 'lbfgs',\n",
        "    alpha = 0.001,\n",
        "    hidden_layer_sizes = (20,),\n",
        "    random_state = 11,\n",
        "    max_iter = 10000\n",
        ")\n",
        "\n",
        "final_lr.fit(x_train.to_numpy(), y_train.to_numpy())\n",
        "final_mlp.fit(x_train.to_numpy(), y_train.to_numpy())"
      ],
      "metadata": {
        "id": "av2cyRv--a8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_lr_predicted = final_lr.predict(x_test.to_numpy())\n",
        "final_lr_accuracy = accuracy_score(y_test, final_lr_predicted)\n",
        "\n",
        "final_mlp_predicted = final_mlp.predict(x_test.to_numpy())\n",
        "final_mlp_accuracy = accuracy_score(y_test, final_mlp_predicted)\n",
        "\n",
        "print(f\"Logistic Regression Model Accuracy = {final_lr_accuracy}\")\n",
        "print(f\"MLPClassifier Model Accuracy = {final_mlp_accuracy}\")\n",
        "\n",
        "# The MLPClassifier did marginally better"
      ],
      "metadata": {
        "id": "SkA1sswq_eS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify which features the MLPClassifier model relies on the most\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "mlp_results = permutation_importance(\n",
        "    final_mlp, x_val, y_val, n_repeats = 10, random_state = 99\n",
        ")\n",
        "\n",
        "mlp_permutation = pd.DataFrame({\n",
        "    \"feature\": x_val.columns,\n",
        "    \"importance\": mlp_results.importances_mean\n",
        "}).sort_values(\"importance\", ascending = False)\n",
        "\n",
        "print(mlp_permutation)"
      ],
      "metadata": {
        "id": "rEVwLtGzKgK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redo featurizing keeping the churn column this time\n",
        "def new_featurize(df):\n",
        "  # 'X' is the df that will hold our converted data\n",
        "  X = df[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "  X['Partner'] = [1 if x=='Yes' else 0 for x in df['Partner']]\n",
        "  X['Dependents'] = [1 if x=='Yes' else 0 for x in df['Dependents']]\n",
        "  X['PhoneService'] = [1 if x=='Yes' else 0 for x in df['PhoneService']]\n",
        "  X['MultipleLines'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['MultipleLines']]\n",
        "  X['InternetService'] = [1 if x=='DSL' else 0 if x=='Fiber optic' else 2 for x in df['InternetService']]\n",
        "  X['OnlineSecurity'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['OnlineSecurity']]\n",
        "  X['OnlineBackup'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['OnlineBackup']]\n",
        "  X['DeviceProtection'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['DeviceProtection']]\n",
        "  X['TechSupport'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['TechSupport']]\n",
        "  X['StreamingTV'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['StreamingTV']]\n",
        "  X['StreamingMovies'] = [1 if x=='Yes' else 0 if x=='No' else 2 for x in df['StreamingMovies']]\n",
        "  X['Contract'] = [1 if x=='Month-to-month' else 0 if x=='One year' else 2 for x in df['Contract']]\n",
        "  X['PaperlessBilling'] = [1 if x=='Yes' else 0 for x in df['PaperlessBilling']]\n",
        "  X['PaymentMethod'] = [1 if x=='Electronic check'\n",
        "                        else 0 if x=='Mailed check'\n",
        "                        else 2 if x=='Bank transfer (automatic)'\n",
        "                        else 3 for x in df['PaymentMethod']]\n",
        "  X['Churn'] = [1 if x=='Yes' else 0 for x in df['Churn']]\n",
        "\n",
        "  return X\n",
        "\n",
        "\n",
        "churn_analysis = new_featurize(churn_data)\n",
        "\n",
        "display(churn_analysis.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AbcllrUNOU7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MonthlyCharges had a high effect on churn rate\n",
        "\n",
        "churn_analysis[\"MonthlyCharges_bin\"] = pd.qcut(\n",
        "    churn_analysis[\"MonthlyCharges\"],\n",
        "    q = 10,\n",
        "    duplicates = \"drop\"\n",
        ")\n",
        "\n",
        "bin_stats = churn_analysis.groupby(\"MonthlyCharges_bin\")[\"Churn\"].mean()\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "bin_stats.plot(kind = \"bar\")\n",
        "plt.ylabel(\"Churn Rate\")\n",
        "plt.xlabel(\"MonthlyCharges (Binned)\")\n",
        "plt.title(\"Churn Rate by MonthlyCharges Decile\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XGa6mUf0Nta_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InternetService churn rate analysis\n",
        "\n",
        "churn_analysis.groupby(\"InternetService\")[\"Churn\"].mean()\n",
        "\n",
        "# 0 means Fiber Optic, they churn the most"
      ],
      "metadata": {
        "id": "VQgEw2qTPeZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"TechSupport\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "OKGle84vR2cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"MultipleLines\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "M_m1lUT9SBlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"OnlineSecurity\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "BY4phh4aSDkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"StreamingMovies\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "8y4_leMUS1mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"Partner\")[\"Churn\"].mean()"
      ],
      "metadata": {
        "id": "N0uzLzAfuxKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"Dependents\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "fi6EuMQlu2mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"PhoneService\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "Rqmlm0RxvBhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"OnlineBackup\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "5Gy9w7JLvFFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"DeviceProtection\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "hmAUPlLrvH-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"StreamingTV\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "kLIR6UC_vW0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"Contract\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "E3AGh5ncvcPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"PaperlessBilling\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "vN9gw5zwvd_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_analysis.groupby(\"PaymentMethod\")[\"Churn\"].mean()\n"
      ],
      "metadata": {
        "id": "oArAqVmFvf_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uo3fva5ae97"
      },
      "outputs": [],
      "source": [
        "'''DATA VISUALIZATION - LR Model Accuracy'''\n",
        "\n",
        "#Setting up Datasets\n",
        "dvcategories = [\"True Positives\", \"True Negatives\", \"False Positives\", \"False Negatives\"]\n",
        "TP= 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "y_test_set = y_test[\"Churn\"].tolist()\n",
        "\n",
        "u=0\n",
        "for y in final_lr_predicted:\n",
        "  if y == 0 and y == y_test_set[u]:\n",
        "    TN += 1\n",
        "  elif y == 1 and y == y_test_set[u]:\n",
        "    TP += 1\n",
        "  elif y == 1 and y!= y_test_set[u]:\n",
        "    FP += 1\n",
        "  elif y == 0 and y != y_test_set[u]:\n",
        "    FN += 1\n",
        "  u+=1\n",
        "\n",
        "print(TP, TN, FP, FN)\n",
        "\n",
        "#Graphing\n",
        "dvcategories = [\"Negative\",\"Positive\"]\n",
        "cat = np.arange(len(dvcategories))\n",
        "w=0.4\n",
        "\n",
        "plt.bar(cat - w/2, [TN, TP], width=.4, label=\"True\")\n",
        "plt.bar(cat+ w/2, [FN, FP], width=.4,label=\"False\")\n",
        "\n",
        "plt.title(\"LR Model Accuracy\")\n",
        "plt.xlabel(\"Positive or Negative?\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.xticks(cat, dvcategories)\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''DATA VISUALIZATION - MLP Model Accuracy'''\n",
        "\n",
        "#Setting up Datasets\n",
        "dvcategories = [\"True Positives\", \"True Negatives\", \"False Positives\", \"False Negatives\"]\n",
        "TP= 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "y_test_set = y_test[\"Churn\"].tolist()\n",
        "\n",
        "u=0\n",
        "for y in final_mlp_predicted:\n",
        "  if y == 0 and y == y_test_set[u]:\n",
        "    TN += 1\n",
        "  elif y == 1 and y == y_test_set[u]:\n",
        "    TP += 1\n",
        "  elif y == 1 and y!= y_test_set[u]:\n",
        "    FP += 1\n",
        "  elif y == 0 and y != y_test_set[u]:\n",
        "    FN += 1\n",
        "  u+=1\n",
        "\n",
        "print(TP, TN, FP, FN)\n",
        "\n",
        "#Graphing\n",
        "dvcategories = [\"Negative\",\"Positive\"]\n",
        "cat = np.arange(len(dvcategories))\n",
        "w=0.4\n",
        "\n",
        "plt.bar(cat - w/2, [TN, TP], width=.4, label=\"True\")\n",
        "plt.bar(cat+ w/2, [FN, FP], width=.4,label=\"False\")\n",
        "\n",
        "plt.title(\"MLP Model Accuracy\")\n",
        "plt.xlabel(\"Positive or Negative?\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.xticks(cat, dvcategories)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "tvjFEY_dk6uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwWYNKB_ah95"
      },
      "outputs": [],
      "source": [
        "'''BIAS AND FAIRNESS EVALUATION'''\n",
        "# Lydia\n",
        "\n",
        "# imports\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# y_test is currently shape (1055, 1) => fix to (1055,)\n",
        "y_true = pd.Series(np.array(y_test).ravel(), index=x_test.index)\n",
        "\n",
        "# convert to yes/no if needed\n",
        "# encoding binary data\n",
        "if y_true.dtype == object:\n",
        "  y_true = y_true.map({\"Yes\": 1, \"No\": 0, \"yes\": 1, \"no\": 0})\n",
        "\n",
        "# 1: build test_df with correct alignment\n",
        "test_df = x_test.copy()\n",
        "test_df[\"y_true\"] = y_true\n",
        "\n",
        "# bring gender back if x_test does not contain\n",
        "sensitive_attr = \"gender\"\n",
        "if sensitive_attr not in test_df.columns:\n",
        "  test_df[sensitive_attr] = df.loc[test_df.index, sensitive_attr]\n",
        "\n",
        "# 2: model predictions\n",
        "test_df[\"pred_lr\"] = final_lr.predict(x_test)\n",
        "test_df[\"pred_mlp\"] = final_mlp.predict(x_test)\n",
        "\n",
        "# 3: fairness metrics by group\n",
        "groups = test_df[sensitive_attr].unique()\n",
        "results = []\n",
        "\n",
        "for model_name, pred_col in [(\"Logistic Regression\", \"pred_lr\"),\n",
        "                             (\"MLP Classifier\", \"pred_mlp\")]:\n",
        "\n",
        "  print(f\"\\nFairness Metrics for {model_name}: \")\n",
        "\n",
        "  for g in groups:\n",
        "    subset = test_df[test_df[sensitive_attr] == g]\n",
        "\n",
        "    if len(subset) == 0:\n",
        "      print(f\"Skipping group '{g}' (0 rows).\")\n",
        "      continue\n",
        "\n",
        "    # no NaNs in the subset labels...?\n",
        "    if subset[\"y_true\"].isna().any():\n",
        "      raise ValueError(f\"NaNs detected in y_true for group '{g} after alignment.\")\n",
        "\n",
        "    acc = accuracy_score(subset[\"y_true\"], subset[pred_col])\n",
        "    prec = precision_score(subset[\"y_true\"], subset[pred_col], zero_division=0)\n",
        "    rec = recall_score(subset[\"y_true\"], subset[pred_col], zero_division=0)\n",
        "    positive_rate = subset[pred_col].mean()\n",
        "\n",
        "    results.append({\n",
        "        \"model\": model_name,\n",
        "        \"gender\": g,\n",
        "        \"count\": len(subset),\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"positive_prediction_rate\": positive_rate\n",
        "    })\n",
        "\n",
        "fairness_df = pd.DataFrame(results)\n",
        "display(fairness_df)\n",
        "\n",
        "# 4: disparate impact / 4/5ths rule for each model\n",
        "print(\"\\nDisparate Impact Analysis: \")\n",
        "\n",
        "for model_name, pred_col in [(\"Logistic Regression\", \"pred_lr\"),\n",
        "                             (\"MLP Classifier\", \"pred_mlp\")]:\n",
        "\n",
        "  print(f\"\\n{model_name}: \")\n",
        "  ppr = test_df.groupby(sensitive_attr)[pred_col].mean()\n",
        "\n",
        "  # if only a single group exists, skip\n",
        "  if len(ppr) < 2:\n",
        "    print(\"Not enough groups to compare.\")\n",
        "    continue\n",
        "\n",
        "  min_group = ppr.idxmin()\n",
        "  max_group = ppr.idxmax()\n",
        "  ratio = ppr[min_group] / ppr[max_group] if ppr[max_group] != 0 else np.nan\n",
        "\n",
        "  print(f\"Lowest PPR group: {min_group} ({ppr[min_group]:.3f})\")\n",
        "  print(f\"Highest PPR group: {max_group} ({ppr[max_group]:.3f})\")\n",
        "  print(f\"Disparate Impact Ratio (low/high): {ratio:.3f}\")\n",
        "\n",
        "  if pd.isna(ratio):\n",
        "    print(\"Ratio is undefined (division by 0).\")\n",
        "  elif ratio < 0.8:\n",
        "    print(\"Potential disparate impact detected (ratio < 0.8).\")\n",
        "  else:\n",
        "    print(\"No disparate impact detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''DEMO'''\n",
        "\n",
        "import pickle\n",
        "\n",
        "lr_file = open(\"lr_model.saved\", \"wb\")\n",
        "pickle.dump(final_lr,lr_file)\n",
        "lr_file.close()\n"
      ],
      "metadata": {
        "id": "hHWWs5i8skJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "open_lr = open(\"lr_model.saved\", \"rb\")\n",
        "model = pickle.load(open_lr)\n",
        "open_lr.close()\n",
        "\n",
        "# sample inputs of someone who is likely to churn\n",
        "tenure = 5\n",
        "monthlycharges = -90\n",
        "totalcharges = -4500\n",
        "partner = 0\n",
        "dependents = 0\n",
        "phoneservice = 1\n",
        "multiplelines = 1\n",
        "internetservice = 0\n",
        "onlinesecurity = 0\n",
        "onlinebackup = 0\n",
        "deviceprot= 0\n",
        "techsupport = 0\n",
        "streamingtv= 0\n",
        "streamingmovies= 0\n",
        "contract= 1\n",
        "paperless = 1\n",
        "payment = 3\n",
        "\n",
        "input_data = np.array([[tenure,monthlycharges,totalcharges,\n",
        "                           partner,dependents,phoneservice,\n",
        "                           multiplelines,internetservice,\n",
        "                           onlinesecurity,onlinebackup,\n",
        "                           deviceprot,techsupport,streamingtv,\n",
        "                           streamingmovies,contract,paperless,\n",
        "                           payment]])\n",
        "\n",
        "demo_predicted = final_lr.predict(input_data)\n",
        "\n",
        "if demo_predicted[0] == 1:\n",
        "  print(\"This person is likely to churn\")\n",
        "\n",
        "if demo_predicted[0] == 0:\n",
        "  print(\"This person is not likely to churn\")"
      ],
      "metadata": {
        "id": "qON0GXoOtZtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample inputs of someone who is not likely to churn\n",
        "tenure = 12\n",
        "monthlycharges = 20\n",
        "totalcharges = 1020\n",
        "partner = 1\n",
        "dependents = 1\n",
        "phoneservice = 1\n",
        "multiplelines = 1\n",
        "internetservice = 0\n",
        "onlinesecurity = 1\n",
        "onlinebackup = 1\n",
        "deviceprot= 1\n",
        "techsupport = 1\n",
        "streamingtv= 1\n",
        "streamingmovies= 1\n",
        "contract= 1\n",
        "paperless = 0\n",
        "payment = 3\n",
        "\n",
        "input_data2 = np.array([[tenure,monthlycharges,totalcharges,\n",
        "                           partner,dependents,phoneservice,\n",
        "                           multiplelines,internetservice,\n",
        "                           onlinesecurity,onlinebackup,\n",
        "                           deviceprot,techsupport,streamingtv,\n",
        "                           streamingmovies,contract,paperless,\n",
        "                           payment]])\n",
        "\n",
        "demo_predicted2 = final_lr.predict(input_data2)\n",
        "\n",
        "if demo_predicted2[0] == 1:\n",
        "  print(\"This person is likely to churn\")\n",
        "\n",
        "if demo_predicted2[0] == 0:\n",
        "  print(\"This person is not likely to churn\")"
      ],
      "metadata": {
        "id": "2iktoftcw68I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}